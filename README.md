


# Convolution Neural Network
this project allows making convolution neural network in a simple way with optimization and regularization
**Requirements**
- [Python](https://www.python.org/) 3.*
- [Numpy](http://www.numpy.org/)


**Options that project support :**
1. modes 
	- train 
	- prediction
2. Neural network layers
3. Weight initializer
	- Random numbers between 0 to 0.9999...   multiplied by 0.01  
	- Random numbers between 0 to 0.9999...   multiplied by   $\sqrt{layer dim[l-1]}$ 
	- HE initializer  Random numbers between 0 to 0.9999...   multiplied by   $\sqrt{2/layer dim[l-1]}$
	- Xavier initializer  Random numbers between 0 to 0.9999...   multiplied by   $\sqrt{1/layer dim[l-1]}$
4. Number of epochs
5. Learning rate 
5. Regularization
	- L2
	- Dropout
7. optimization
	- Momentum
	-  Adam 
8. Save model weights 
9. Load model weights

## Data loader 

to load your data there is file `data.py` has two function you should write your logic for loading data in it 
	

 1. train data loader
	```py	
	def train_data_loader(path=None):
	   X_train = None
	   Y_train = None
	   X_test = None
	   Y_test = None
	   n_classes = None
	  
	   ### Write your logic here ###
	   
	   
	   Y_train = one_hot_encode(Y_train, n_classes)
	   Y_test = one_hot_encode(Y_test, n_classes)
	   
	   return X_train, Y_train, X_test, Y_test
	```

2. predict data loader
	```py
	def predict_data_loader(path=None):
	    X = None
	    
	    ### Write your logic here ###
	    
	    return X
	```
## Run
To Run this project and make your CNN model you have to know to tell the CNN project what you want to do 

**Modes**
	your should chose one mode of two mode
	- train
		`python run.py --train True`
	- predict
		`python run.py --predict True`

### Train Mode
in train mode you have to define some parameters subset is required and the other is optional 

**Required parameters**
- conv - filters size and stride ,pading for convolution and pooling layer 
	`Ex: --conv "conv1 2 8 2 0 => pool1 2 2 max => conv2 2 16 2 0 => pool2 2 2 max "`
	* conv - filter size, number of filters, stride, pading 
	* pool - filter size, stride , mode
-  fc	--   number of neurons in every layer 
	```py 
	Ex: --fc 3 5 3 1           
			*	
		*	*	*
		*	*	*	*    
		*	*	*
			*
	```
- n_epochs -- number of iterations of training 
	 `Ex: --n_epochs 30000`
- learning_rate -- form it's name learning rate for training 
	`Ex: --learning_rate 0.001`
- data_path -- path of the data set if the data set is loaded not generated 
	`Ex: --data_path /dir1/dir2/file.csv`

**Optional parameters**
- initialier -- chose the weight initializer algorithm 
	* `--initializer 1`  Random numbers between 0 to 0.9999...   multiplied by 0.01  
	* `--initializer 2`  HE initializer
	* `--initializer 3`  Xavier initializer
	* the default one is :	random numbers between 0 to 0.9999...   multiplied by   $$ \sqrt{layer dim[l-1]} $$	 
- batch size
	* `Ex: --batch_size 64` create data set split in batches each batch have 64 example except last one may be less than 64
	* `--batch_size 1` stochastic gradient descent 
	* the default on is  gradient descent 
- shuffle -- shuffling data set
	* `--shuffle Ture` shuffle data 
	* data not shuffled by default
- Regularization methods -- there are two methods you can chose between them.
	* L2 regularization -- you can chose L2 regularization method by initialize the parameter lambd
		`Ex: --lambd 0.7`
	* Dropout -- you can chose dropout method by initialize the parameter keep_prob 
		`Ex: --keep_prob 0.86`
- Optimization methods --  there are two methods you can chose between them.
	* Momentum -- you can chose momentum optimization method by initialize the parameter beta1
		* beta1 -- velocity 
		`--beta1 0.9`
	* Adam -- you can chose Adam optimization method by initialize the parameters beta1, beta2 and epsilon
		* beta1 -- velocity 
		* beta2 -- s 
		* epsilon -- very small number to avoid dividing by zero it's default value is 1e-8
		`--beta1 0.9 --beta2 0.999 --epsilon 1e-9`
- Saving path -- file with path you want to save trained parameters in it
	`Ex: --saving_path dir/model.npy`
- Print Accuracy -- bool variable is set to display the accuracy of the model or not, it's default is True
	`Ex: --print_accuracy False`



### Predict Mode
**Required parameters**
- loading_path -- path of trained weights file
	`Ex: loading_path dir/model.npy`
- data_path -- path of the data set if the data set is loaded not generated 
	`Ex: --data_path /dir1/dir2/file.csv`

**Optional parameters**
	- data_path -- path of the data set if the data set is generated by predict_data_loader function
